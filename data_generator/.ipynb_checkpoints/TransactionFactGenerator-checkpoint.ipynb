{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d69aab3-b906-4105-8237-7b027a293188",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH_PREFIX = 'cfg/'\n",
    "CONFIG_TMP_FILE_PATH_PREFIX = 'cfg/tmp/'\n",
    "CONFIG_BACKUP_FILE_PATH_PREFIX = 'cfg/backup/'\n",
    "\n",
    "OUTPUT_FILE_PATH_PREFIX = 'output/'\n",
    "OUTPUT_TMP_FILE_PATH_PREFIX = 'output/tmp/'\n",
    "\n",
    "CONFIG_NUMBER = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab98e876-82f7-4120-b48c-3a90fd026ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d99565-fce1-478a-bef1-982859553d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/22 13:19:16 WARN Utils: Your hostname, htknphuong-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.142.129 instead (on interface ens33)\n",
      "22/11/22 13:19:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/22 13:19:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/22 13:19:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/22 13:19:18 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark Customer Fact Generator\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893b0b34-99fc-4fe0-ad17-bdd7204f829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "accountid is exist\n",
      "begin loadingaccountid\n",
      "defaultaccountid is exist\n",
      "begin loadingdefaultaccountid\n",
      "transactionid is not exist\n",
      "begin to creating transactionid\n"
     ]
    }
   ],
   "source": [
    "##Reading the config from file for max id\n",
    "import os.path\n",
    "idConfig = {\n",
    "    \"accountid\": 10000000,\n",
    "    \"defaultaccountid\": 10000000,\n",
    "    \"transactionid\": 0\n",
    "}\n",
    "print('-----------------')\n",
    "for file in idConfig.keys():\n",
    "    file_exist = os.path.exists(CONFIG_FILE_PATH_PREFIX+file)\n",
    "    if (file_exist):\n",
    "        print(file + ' is exist')\n",
    "        print('begin loading' + file)\n",
    "        realFile = open(CONFIG_FILE_PATH_PREFIX+file,\"r\")\n",
    "        idConfig[file] = int(realFile.readlines()[0])\n",
    "        realFile.close()\n",
    "    else:\n",
    "        if (file not in [\"transactionid\"]):\n",
    "            print ('Please run CustomerFactGenerator first')\n",
    "            break\n",
    "        print(file + ' is not exist')\n",
    "        print('begin to creating ' + file)\n",
    "        realFile = open(CONFIG_FILE_PATH_PREFIX+file,\"w+\")\n",
    "        realFile.seek(0)\n",
    "        realFile.write(str(idConfig[file]))\n",
    "        realFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd611695-b603-4fca-b63c-66d199c2e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accountid': 10001004, 'defaultaccountid': 10000000, 'transactionid': 0}\n"
     ]
    }
   ],
   "source": [
    "print(idConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f71e7d9c-06de-4226-833b-527fb72a6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import faker\n",
    "from datetime import datetime\n",
    "import re\n",
    "class TransactionObject:\n",
    "    TypeTransactionDim = {\n",
    "        1: \"cash withdrawals\",\n",
    "        2: \"online payments\",\n",
    "        3: \"debit card charges\",\n",
    "        4: \"wire transfers\",\n",
    "    }\n",
    "    ConcurrencyDim = {\n",
    "        1: \"VND\",\n",
    "        2: \"USD\",\n",
    "        3: \"SIG\"\n",
    "    }\n",
    "    TransactionPointDim = {\n",
    "        1: \"Banking App\",\n",
    "        2: \"ATM\",\n",
    "        3: \"Bank branch\"\n",
    "    }\n",
    "    fake = faker.Faker()\n",
    "\n",
    "    def __init__(self):\n",
    "        self.transactionid = idConfig[\"accountid\"]\n",
    "        idConfig[\"accountid\"] += 1\n",
    "        self.amount = random.randint(1, 10000)\n",
    "        self.timestamp = TransactionObject.fake.date()\n",
    "        __concurrency = random.choice(list(TransactionObject.ConcurrencyDim.keys()))\n",
    "        self.concurrency = TransactionObject.ConcurrencyDim[__concurrency]\n",
    "        __transactionpoint = random.choice(list(TransactionObject.TransactionPointDim.keys()))\n",
    "        self.transactionpoint = TransactionObject.TransactionPointDim[__transactionpoint]\n",
    "        \n",
    "        __typetransaction = random.choice(list(TransactionObject.TypeTransactionDim.keys()))\n",
    "        self.typetransaction = random.choice(list(TransactionObject.TypeTransactionDim.keys()))\n",
    "            \n",
    "        self.destinationaccountid = random.randint(idConfig['defaultaccountid'], idConfig['accountid'])\n",
    "        self.accountid = random.randint(idConfig['defaultaccountid'], idConfig['accountid'])\n",
    "        \n",
    "        self.exchangerate = 1\n",
    "        self.lattitude = random.uniform(-85, 85)\n",
    "        self.longtitude = random.uniform(-180, 180)\n",
    "\n",
    "\n",
    "    def toList(self):\n",
    "        return [Row(\n",
    "            self.transactionid,\n",
    "            self.amount,\n",
    "            self.timestamp,\n",
    "            self.typetransaction,\n",
    "            self.concurrency,\n",
    "            self.transactionpoint,\n",
    "            self.destinationaccountid,\n",
    "            self.accountid,\n",
    "            self.exchangerate,\n",
    "            self.lattitude,\n",
    "            self.longtitude\n",
    "            )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86d26b9b-4b71-4a6b-8813-10754218bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransactionAccount = []\n",
    "for x in range(CONFIG_NUMBER):\n",
    "    Transaction = TransactionObject().toList()\n",
    "    TransactionAccount = TransactionAccount + Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "251b08e7-5e08-43b5-9e6e-fb4d53c2daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FactTransactionColumns = StructType([\n",
    "    StructField(\"transactionid\", StringType(), True),\n",
    "    StructField(\"amount\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    StructField(\"typetransaction\", StringType(), True),\n",
    "    StructField(\"concurrency\", StringType(), True),\n",
    "    StructField(\"transactionpoint\", StringType(), True),\n",
    "    StructField(\"destinationaccountid\", StringType(), True),\n",
    "    StructField(\"accountid\", StringType(), True),\n",
    "    StructField(\"exchangerate\", StringType(), True),\n",
    "    StructField(\"lattitude\", StringType(), True),\n",
    "    StructField(\"longtitude\", StringType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d7857b3-e534-4e7a-88bc-d75ff5971e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MainDf = spark.createDataFrame(data=TransactionAccount, schema = FactTransactionColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c342c4a-150c-46f4-ad80-67bfec477788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "fileName = 'FactTransaction ' + now.strftime(\"%Y-%m-%d %H-%M-%S-%f\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4bd8685-c5ce-4b52-9a93-8b9e537bed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FactTransaction 2022-11-22 14-47-43-251365\n"
     ]
    }
   ],
   "source": [
    "print(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "711e21df-6844-4cbc-83ac-422bb000b028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "MainDf.write.mode('overwrite').option(\"header\",\"true\").csv(OUTPUT_TMP_FILE_PATH_PREFIX + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92271101-1a94-4b1b-a828-2139c52a148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to rewrite accountid\n",
      "-----------------\n",
      "begin to rewrite defaultaccountid\n",
      "-----------------\n",
      "begin to rewrite transactionid\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for file in idConfig.keys():\n",
    "    print('begin to rewrite ' + file)\n",
    "    realFile = open(CONFIG_TMP_FILE_PATH_PREFIX+file,\"w+\")\n",
    "    realFile.seek(0)\n",
    "    realFile.write(str(idConfig[file]))\n",
    "    realFile.close()\n",
    "    print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "556d2228-b5ab-45e9-813c-c56cb66575fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/FactTransaction 2022-11-22 14-47-43-251365'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "for file in idConfig.keys():\n",
    "    shutil.move(CONFIG_FILE_PATH_PREFIX+file, CONFIG_BACKUP_FILE_PATH_PREFIX+file)\n",
    "    shutil.move(CONFIG_TMP_FILE_PATH_PREFIX+file, CONFIG_FILE_PATH_PREFIX+file)\n",
    "shutil.move(OUTPUT_TMP_FILE_PATH_PREFIX + fileName, OUTPUT_FILE_PATH_PREFIX+fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0d0dd-f02a-4e93-8595-c2bfd94aad43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
